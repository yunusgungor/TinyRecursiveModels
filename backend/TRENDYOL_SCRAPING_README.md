# Trendyol Scraping Entegrasyonu

## ğŸ”„ DeÄŸiÅŸiklikler

Trendyol'un gerÃ§ek bir API'si olmadÄ±ÄŸÄ± iÃ§in, backend'deki `TrendyolAPIService` modÃ¼lÃ¼ **web scraping** tabanlÄ± bir implementasyona dÃ¶nÃ¼ÅŸtÃ¼rÃ¼ldÃ¼.

### YapÄ±lan DeÄŸiÅŸiklikler

1. **Yeni Scraping Servisi**: `trendyol_scraping_service.py` oluÅŸturuldu
   - `scraping/scrapers/trendyol_scraper.py` modÃ¼lÃ¼nÃ¼ kullanÄ±r
   - Mevcut API servisinin aynÄ± interface'ini korur
   - Cache mekanizmasÄ± korundu
   - Rate limiting eklendi (scraping iÃ§in daha dÃ¼ÅŸÃ¼k)

2. **Geriye DÃ¶nÃ¼k Uyumluluk**: `trendyol_api.py` wrapper olarak gÃ¼ncellendi
   - Eski import'lar Ã§alÄ±ÅŸmaya devam eder
   - Mevcut kod deÄŸiÅŸiklik gerektirmez

3. **BaÄŸÄ±mlÄ±lÄ±klar**: `backend/requirements.txt` gÃ¼ncellendi
   - `playwright==1.40.0`
   - `beautifulsoup4==4.12.2`
   - `lxml==4.9.3`

## ğŸš€ Kurulum

### 1. Backend BaÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± YÃ¼kleyin

```bash
cd backend
pip install -r requirements.txt
```

### 2. Playwright Browser'Ä± Kurun

```bash
playwright install chromium
```

### 3. Scraping BaÄŸÄ±mlÄ±lÄ±klarÄ±nÄ± Kontrol Edin

```bash
cd ../scraping
pip install -r requirements.txt
```

## ğŸ“– KullanÄ±m

### Kod DeÄŸiÅŸikliÄŸi Gerekmiyor

Mevcut backend kodu aynen Ã§alÄ±ÅŸmaya devam eder! Servis otomatik olarak scraping kullanacak:

```python
from app.services.trendyol_api import get_trendyol_service

# AynÄ± API
service = get_trendyol_service()

# Ama ÅŸimdi scraping kullanÄ±yor
products = await service.search_products(
    category="elektronik",
    keywords=["kulaklÄ±k"],
    max_results=20
)
```

### Servis DetaylarÄ±

#### TrendyolScrapingService

Ã–zellikler:
- âœ… **Cache**: 30 dakika TTL (varsayÄ±lan)
- âœ… **Rate Limiting**: Dakikada 20 istek (bottan kaÃ§Ä±nmak iÃ§in)
- âœ… **Browser Management**: Otomatik Playwright yÃ¶netimi
- âœ… **Anti-Bot**: User agent rotation, human simulation
- âœ… **Fallback**: Cache'den eski veri kullanma

Ana Metodlar:
```python
# ÃœrÃ¼n arama
await service.search_products(
    category: str,
    keywords: List[str],
    max_results: int = 50,
    min_price: Optional[float] = None,
    max_price: Optional[float] = None
)

# ÃœrÃ¼n detayÄ±
await service.get_product_details(product_id: str)

# GiftItem'a dÃ¶nÃ¼ÅŸtÃ¼rme
service.convert_to_gift_item(product: TrendyolProduct)

# Temizlik
await service.close()
```

## âš™ï¸ KonfigÃ¼rasyon

### Rate Limiting

Scraping servisi iÃ§in:
```python
service = TrendyolScrapingService(
    rate_limit=20,  # Dakikada max istek sayÄ±sÄ±
    cache_ttl=1800  # Cache sÃ¼resi (saniye)
)
```

### Kategori Mapping

Desteklenen kategoriler:
- `elektronik`
- `ev_yasam` / `ev`
- `kozmetik`
- `giyim` / `kadin` / `erkek`
- `cocuk`
- `ayakkabi`
- `supermarket`
- `mobilya`
- `spor`
- `kitap`

## ğŸ”§ Sorun Giderme

### CAPTCHA Detected

EÄŸer scraping sÄ±rasÄ±nda CAPTCHA ile karÅŸÄ±laÅŸÄ±lÄ±rsa:
1. Rate limit'i dÃ¼ÅŸÃ¼rÃ¼n
2. Delay sÃ¼resini artÄ±rÄ±n
3. Biraz bekleyip tekrar deneyin

```python
# scraping/config/scraping_config.yaml iÃ§inde:
rate_limit:
  requests_per_minute: 10  # Daha dÃ¼ÅŸÃ¼k
  delay_between_requests: [3, 7]  # Daha uzun
```

### Browser BaÅŸlatma HatasÄ±

Playwright browser kurulumu gerekli:
```bash
playwright install chromium
playwright install-deps  # Linux'ta sistem baÄŸÄ±mlÄ±lÄ±klarÄ± iÃ§in
```

### Import Error

`scraping` klasÃ¶rÃ¼ bulunamÄ±yor hatasÄ±:
- Scraping klasÃ¶rÃ¼ backend'in parent dizininde olmalÄ±
- Path otomatik olarak ekleniyor: `SCRAPING_DIR = Path(__file__).parent.parent.parent.parent / "scraping"`

### Selector GÃ¼ncellemeleri

Trendyol sitesi deÄŸiÅŸtiyse:
1. `scraping/scrapers/trendyol_scraper.py` dosyasÄ±nÄ± aÃ§Ä±n
2. `SELECTORS` dictionary'sini gÃ¼ncelleyin
3. Browser developer tools ile yeni selector'larÄ± bulun

## ğŸ“Š Performans

### HÄ±z KarÅŸÄ±laÅŸtÄ±rmasÄ±

- **API Modu** (varsayÄ±msal): ~100-200ms/istek
- **Scraping Modu**: ~3-5 saniye/Ã¼rÃ¼n
  - Browser baÅŸlatma: ~2 saniye
  - Sayfa yÃ¼kleme: ~1-2 saniye
  - Data extraction: ~0.5-1 saniye

### Optimizasyonlar

1. **Cache KullanÄ±mÄ±**: Ä°lk istek yavaÅŸ, sonrakiler cache'den hÄ±zlÄ±
2. **Browser Reuse**: Singleton pattern ile browser yeniden kullanÄ±lÄ±r
3. **Batch Processing**: Birden fazla Ã¼rÃ¼nÃ¼ aynÄ± browser session'da iÅŸle

## ğŸ§ª Test

Backend testleri gÃ¼ncellenmesi gerekebilir:

```python
# Mock scraping service
@pytest.fixture
def mock_trendyol_service():
    service = Mock(spec=TrendyolScrapingService)
    service.search_products.return_value = [...]
    return service
```

## ğŸ“ Notlar

- Scraping, API'ye gÃ¶re daha yavaÅŸ ancak daha gÃ¼venilirdir
- Rate limiting bottan kaÃ§Ä±nmak iÃ§in kritiktir
- Cache kullanÄ±mÄ± performans iÃ§in Ã¶nemlidir
- Production'da headless=True kullanÄ±n
- Development'ta headless=False ile debug yapabilirsiniz

## ğŸ” Yasal UyarÄ±

Web scraping yaparken:
- robots.txt'ye uyun
- Rate limiting kullanÄ±n
- Site'ye zarar vermeyin
- Telif haklarÄ±na saygÄ± gÃ¶sterin
- KullanÄ±m koÅŸullarÄ±nÄ± okuyun
