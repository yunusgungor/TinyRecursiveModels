# TRM & Gift Recommendation System

## Proje HakkÄ±nda

Bu proje iki ana bileÅŸenden oluÅŸur:

1. **TRM (Tiny Recursion Model)**: 7M parametreli recursive reasoning
2. **Gift Recommendation**: RL tabanlÄ± hediye Ã¶nerisi sistemi

## TRM: Recursive Reasoning

### BaÅŸarÄ± OranlarÄ±

| Dataset | BaÅŸarÄ± | Parametre |
|---------|--------|-----------|
| ARC-AGI-1 | %45 | 7M |
| ARC-AGI-2 | %8 | 7M |
| Sudoku | %95+ | 7M |
| Maze | %90+ | 7M |

### NasÄ±l Ã‡alÄ±ÅŸÄ±r?

TRM, recursive olarak cevabÄ±nÄ± iyileÅŸtirir:
1. BaÅŸlangÄ±Ã§: x (soru), y (cevap), z (gizli durum)
2. K adÄ±m boyunca: z'yi gÃ¼ncelle, y'yi iyileÅŸtir
3. SonuÃ§: Progressif olarak iyileÅŸtirilmiÅŸ cevap

## Hediye Ã–nerisi Sistemi

### Temel Ã–zellikler

1. **Tool-Enhanced Architecture**: 5 akÄ±llÄ± araÃ§
2. **Integrated Enhanced TRM**: Ã‡ok bileÅŸenli model
3. **Curriculum Learning**: 4 aÅŸamalÄ± Ã¶ÄŸrenme
4. **SDV Sentetik Veri**: 3 farklÄ± yÃ¶ntem
5. **Web Scraping**: 4 TÃ¼rk e-ticaret sitesi

### AraÃ§lar

- `price_comparison`: BÃ¼tÃ§eye uygun Ã¼rÃ¼nler
- `review_analysis`: YÃ¼ksek puanlÄ± Ã¼rÃ¼nler
- `inventory_check`: Stok kontrolÃ¼
- `trend_analyzer`: Trend analizi
- `budget_optimizer`: BÃ¼tÃ§e optimizasyonu


## Kurulum

### Gereksinimler

- Python 3.10+
- CUDA 12.6.0+ (GPU iÃ§in)
- 8GB+ RAM (CPU), 16GB+ VRAM (GPU)

### AdÄ±m 1: Temel Kurulum

```bash
git clone <repository-url>
cd TinyRecursiveModels

python -m venv venv
source venv/bin/activate  # Linux/Mac
# veya venv\Scripts\activate  # Windows

pip install --upgrade pip wheel setuptools
pip install --pre --upgrade torch torchvision torchaudio
pip install -r requirements.txt
pip install --no-cache-dir --no-build-isolation adam-atan2

wandb login YOUR-LOGIN  # Opsiyonel
```

### AdÄ±m 2: SDV Kurulumu

```bash
chmod +x setup_sdv.sh
./setup_sdv.sh

# veya manuel
pip install sdv>=1.0.0 pandas>=1.5.0
```

## HÄ±zlÄ± BaÅŸlangÄ±Ã§

### TRM ile ARC-AGI

```bash
# Veri hazÄ±rlama
python -m dataset.build_arc_dataset \
  --input-file-prefix kaggle/combined/arc-agi \
  --output-dir data/arc1concept-aug-1000 \
  --subsets training evaluation concept

# Model eÄŸitimi (4 GPU)
torchrun --nproc-per-node 4 pretrain.py \
  arch=trm \
  data_paths="[data/arc1concept-aug-1000]" \
  arch.L_layers=2 arch.H_cycles=3 arch.L_cycles=4 \
  ema=True
```

### Hediye Ã–nerisi

```bash
# 1. Veri oluÅŸtur
python create_gift_data.py

# 2. Sentetik veri Ã¼ret
python sdv_advanced_generator.py

# 3. Test et
python test_tool_integration.py

# 4. Model eÄŸit
python train_integrated_enhanced_model.py \
  --epochs 150 --batch_size 16

# 5. Fine-tune
python finetune_category_diversity.py
```


## Proje YapÄ±sÄ±

```
TinyRecursiveModels/
â”œâ”€â”€ README.md                          # Bu dosya
â”œâ”€â”€ QUICK_START.md                     # HÄ±zlÄ± baÅŸlangÄ±Ã§
â”œâ”€â”€ SDV_README.md                      # SDV kÄ±lavuzu
â”œâ”€â”€ SDV_KULLANIM_KILAVUZU.md          # DetaylÄ± SDV
â”œâ”€â”€ SDV_DOSYA_YAPISI.md               # SDV yapÄ±sÄ±
â”‚
â”œâ”€â”€ config/                            # YapÄ±landÄ±rma
â”‚   â”œâ”€â”€ cfg_pretrain.yaml             # TRM config
â”‚   â”œâ”€â”€ tool_enhanced_gift_recommendation.yaml
â”‚   â”œâ”€â”€ sdv_config.yaml
â”‚   â””â”€â”€ arch/                         # Model mimarileri
â”‚
â”œâ”€â”€ models/                            # Model implementasyonlarÄ±
â”‚   â”œâ”€â”€ recursive_reasoning/          # TRM modelleri
â”‚   â”‚   â”œâ”€â”€ trm.py                    # Ana TRM
â”‚   â”‚   â”œâ”€â”€ hrm.py                    # HRM
â”‚   â”‚   â””â”€â”€ transformers_baseline.py
â”‚   â”œâ”€â”€ tools/                        # Tool-enhanced
â”‚   â”‚   â”œâ”€â”€ integrated_enhanced_trm.py
â”‚   â”‚   â”œâ”€â”€ tool_registry.py
â”‚   â”‚   â”œâ”€â”€ gift_tools.py
â”‚   â”‚   â””â”€â”€ enhanced_tool_selector.py
â”‚   â”œâ”€â”€ rl/                           # RL bileÅŸenleri
â”‚   â”‚   â”œâ”€â”€ environment.py
â”‚   â”‚   â”œâ”€â”€ trainer.py
â”‚   â”‚   â”œâ”€â”€ rewards.py
â”‚   â”‚   â””â”€â”€ enhanced_*.py
â”‚   â”œâ”€â”€ common.py                     # Ortak fonksiyonlar
â”‚   â”œâ”€â”€ layers.py                     # Model katmanlarÄ±
â”‚   â”œâ”€â”€ losses.py                     # Loss fonksiyonlarÄ±
â”‚   â””â”€â”€ sparse_embedding.py           # Sparse embeddings
â”‚
â”œâ”€â”€ dataset/                           # Veri hazÄ±rlama
â”‚   â”œâ”€â”€ build_arc_dataset.py
â”‚   â”œâ”€â”€ build_sudoku_dataset.py
â”‚   â”œâ”€â”€ build_maze_dataset.py
â”‚   â””â”€â”€ common.py
â”‚
â”œâ”€â”€ scraping/                          # Web scraping
â”‚   â”œâ”€â”€ scrapers/                     # Site scrapers
â”‚   â”œâ”€â”€ services/                     # Gemini AI, dataset
â”‚   â”œâ”€â”€ utils/                        # Logger, validator
â”‚   â””â”€â”€ config/                       # Scraping config
â”‚
â”œâ”€â”€ evaluators/                        # DeÄŸerlendirme
â”‚   â””â”€â”€ arc.py                        # ARC evaluator
â”‚
â”œâ”€â”€ utils/                             # YardÄ±mcÄ± fonksiyonlar
â”‚   â””â”€â”€ functions.py
â”‚
â”œâ”€â”€ data/                              # Veri klasÃ¶rÃ¼
â”‚   â”œâ”€â”€ realistic_gift_catalog.json
â”‚   â”œâ”€â”€ synthetic_gift_catalog.json
â”‚   â”œâ”€â”€ fully_learned_synthetic_gifts.json
â”‚   â”œâ”€â”€ scraped_gift_catalog.json
â”‚   â””â”€â”€ expanded_user_scenarios.json
â”‚
â”œâ”€â”€ checkpoints/                       # Model checkpoints
â”‚   â”œâ”€â”€ integrated_enhanced/
â”‚   â””â”€â”€ finetuned/
â”‚
â”œâ”€â”€ tests/                             # Test dosyalarÄ±
â”‚   â”œâ”€â”€ test_tool_integration.py      # 5 temel test
â”‚   â”œâ”€â”€ test_comprehensive_improvements.py  # 25+ test
â”‚   â”œâ”€â”€ test_active_tool_usage.py     # Aktif araÃ§
â”‚   â”œâ”€â”€ test_user_scenarios.py
â”‚   â””â”€â”€ test_quick.py
â”‚
â””â”€â”€ scripts/                           # Ana scriptler
    â”œâ”€â”€ pretrain.py                   # TRM pretrain
    â”œâ”€â”€ train_integrated_enhanced_model.py
    â”œâ”€â”€ finetune_category_diversity.py
    â”œâ”€â”€ sdv_data_generator.py
    â”œâ”€â”€ sdv_advanced_generator.py
    â”œâ”€â”€ generate_fully_learned_synthetic.py
    â”œâ”€â”€ create_gift_data.py
    â”œâ”€â”€ run_pipeline_root.py
    â”œâ”€â”€ puzzle_dataset.py
    â””â”€â”€ example_sdv_usage.py
```


## Veri HazÄ±rlama

### TRM Veri Setleri

#### ARC-AGI-1
```bash
python -m dataset.build_arc_dataset \
  --input-file-prefix kaggle/combined/arc-agi \
  --output-dir data/arc1concept-aug-1000 \
  --subsets training evaluation concept \
  --test-set-name evaluation
```

#### ARC-AGI-2
```bash
python -m dataset.build_arc_dataset \
  --input-file-prefix kaggle/combined/arc-agi \
  --output-dir data/arc2concept-aug-1000 \
  --subsets training2 evaluation2 concept \
  --test-set-name evaluation2
```

#### Sudoku-Extreme
```bash
python dataset/build_sudoku_dataset.py \
  --output-dir data/sudoku-extreme-1k-aug-1000 \
  --subsample-size 1000 --num-aug 1000
```

#### Maze-Hard
```bash
python dataset/build_maze_dataset.py
```

### Hediye Ã–nerisi Veri Setleri

#### 1. Temel GerÃ§ek Veri
```bash
python create_gift_data.py
```
**Ã‡Ä±ktÄ±:**
- `data/realistic_gift_catalog.json` (30 Ã¼rÃ¼n, 10+ kategori)
- `data/realistic_user_scenarios.json` (8 Ã§eÅŸitli senaryo)

#### 2. SDV Sentetik Veri

**Temel Ãœretim (Gaussian Copula):**
```bash
python sdv_data_generator.py
```
- Ã‡Ä±ktÄ±: 200 sentetik Ã¼rÃ¼n
- SÃ¼re: ~30 saniye
- Kalite: Orta

**GeliÅŸmiÅŸ Ãœretim (CTGAN/TVAE):**
```bash
python sdv_advanced_generator.py
```
- Ã‡Ä±ktÄ±: 300 Ã¼rÃ¼n + 150 kullanÄ±cÄ± + kalite raporu
- SÃ¼re: ~5 dakika
- Kalite: YÃ¼ksek (>0.80)

**Tamamen Ã–ÄŸrenilmiÅŸ (Scraped Data):**
```bash
python generate_fully_learned_synthetic.py
```
- Ã‡Ä±ktÄ±: 500 Ã¼rÃ¼n + 300 kullanÄ±cÄ±
- Ã–zellik: GerÃ§ek Ã¼rÃ¼n isimleri, tag'ler, fiyat aralÄ±klarÄ±
- Kalite: Ã‡ok YÃ¼ksek (>0.85)

#### 3. Web Scraping
```bash
python run_pipeline_root.py --config config/scraping_config.yaml
```
**Desteklenen Siteler:**
- Trendyol
- Hepsiburada
- Ã‡iÃ§ek Sepeti
- Cimri

**Pipeline AÅŸamalarÄ±:**
1. Scraping (paralel)
2. Validation (duplicate removal)
3. Gemini AI Enhancement
4. Dataset Generation


## Model EÄŸitimi

### TRM EÄŸitimi

#### ARC-AGI-1 (4x H100 GPU, ~3 gÃ¼n)
```bash
torchrun --nproc-per-node 4 --rdzv_backend=c10d \
  --rdzv_endpoint=localhost:0 --nnodes=1 pretrain.py \
  arch=trm \
  data_paths="[data/arc1concept-aug-1000]" \
  arch.L_layers=2 arch.H_cycles=3 arch.L_cycles=4 \
  ema=True
```

#### Sudoku-Extreme (1x L40S GPU, <36 saat)
```bash
python pretrain.py \
  arch=trm \
  data_paths="[data/sudoku-extreme-1k-aug-1000]" \
  epochs=50000 eval_interval=5000 \
  lr=1e-4 weight_decay=1.0 \
  arch.L_layers=2 arch.H_cycles=3 arch.L_cycles=6 \
  ema=True
```

#### Maze-Hard (4x L40S GPU, <24 saat)
```bash
torchrun --nproc-per-node 4 pretrain.py \
  arch=trm \
  data_paths="[data/maze-30x30-hard-1k]" \
  epochs=50000 eval_interval=5000 \
  arch.L_layers=2 arch.H_cycles=3 arch.L_cycles=4 \
  ema=True
```

### Hediye Ã–nerisi EÄŸitimi

#### SÄ±fÄ±rdan EÄŸitim
```bash
python train_integrated_enhanced_model.py \
  --epochs 150 \
  --batch_size 16
```

**EÄŸitim Ã–zellikleri:**
- Gradient accumulation (2 steps)
- Learning rate scheduling (ReduceLROnPlateau)
- Early stopping (25 patience)
- Curriculum learning (4 stages)
- Multi-component loss (6 components)

**EÄŸitim Ã‡Ä±ktÄ±sÄ±:**
```
ğŸš€ INTEGRATED ENHANCED TRM TRAINING
============================================================
ğŸ“± Device: cuda
ğŸ§  Model parameters: 2,345,678
ğŸ“Š Training scenarios: 80
ğŸ“Š Validation scenarios: 20

ğŸ“š Epoch 1/150 - Curriculum Stage 0 - Tools: ['price_comparison']
Training - Total Loss: 0.4523, Category: 0.1234, Tool: 0.0876
          Tool Exec: 0.0543, Tool Reward: 0.156

ğŸ“š Epoch 5/150
ğŸ” Evaluating model...
Evaluation - Category Match: 65.0%, Tool Match: 55.0%
            Tool Exec Success: 0.350, Avg Reward: 0.550
            Quality: 0.517
ğŸ’¾ New best model saved! Score: 0.517
```

#### Checkpoint'ten Devam
```bash
python train_integrated_enhanced_model.py \
  --resume checkpoints/integrated_enhanced/integrated_enhanced_best.pt \
  --epochs 150
```

#### Fine-Tuning (Kategori Ã‡eÅŸitliliÄŸi)
```bash
python finetune_category_diversity.py
```

**Fine-Tuning Ã–zellikleri:**
- Sadece kategori parametrelerini optimize eder
- Ã‡ok dÃ¼ÅŸÃ¼k learning rate (1e-5)
- Diversity loss + label smoothing
- 10 epoch, ~30 dakika


## Test ve DeÄŸerlendirme

### Test Suites

#### 1. Temel Tool Integration (5 test)
```bash
python test_tool_integration.py
```

**Testler:**
- âœ… Device handling (CPU/GPU)
- âœ… Tool parameters generation
- âœ… Tool feedback integration
- âœ… Checkpoint save/load
- âœ… Gradient flow

**Beklenen Ã‡Ä±ktÄ±:**
```
ğŸ‰ ALL TESTS PASSED! ğŸ‰
5/5 tests passed
```

#### 2. KapsamlÄ± Ä°yileÅŸtirmeler (10 kategori, 25+ test)
```bash
python test_comprehensive_improvements.py
```

**Test Kategorileri:**
1. Device Handling (2 test)
2. Tool Feedback Integration (2 test)
3. Tool Parameters Generation (2 test)
4. Tool Execution (4 test)
5. Checkpoint Save/Load (2 test)
6. Training Integration (3 test)
7. Curriculum Learning (1 test)
8. Tool Statistics (2 test)
9. Helper Methods (1 test)
10. Integration Tests (2 test)

#### 3. Aktif AraÃ§ KullanÄ±mÄ± (5 test)
```bash
python test_active_tool_usage.py
```

**Testler:**
- Tek araÃ§ Ã§alÄ±ÅŸtÄ±rma
- Ã‡oklu araÃ§ Ã§alÄ±ÅŸtÄ±rma
- Model forward pass ile araÃ§ kullanÄ±mÄ±
- AraÃ§ geri bildirimi dÃ¶ngÃ¼sÃ¼
- EÄŸitim adÄ±mÄ±nda araÃ§ kullanÄ±mÄ±

#### 4. KullanÄ±cÄ± SenaryolarÄ±
```bash
python test_user_scenarios.py
```

#### 5. HÄ±zlÄ± Test
```bash
python test_quick.py
```

### Beklenen Metrikler

| Metrik | Hedef | Mevcut | AÃ§Ä±klama |
|--------|-------|--------|----------|
| Category Match Rate | >70% | ~75% | DoÄŸru kategori seÃ§imi |
| Tool Match Rate | >60% | ~65% | DoÄŸru araÃ§ seÃ§imi |
| Tool Exec Success | >0.50 | ~0.55 | BaÅŸarÄ±lÄ± araÃ§ Ã§alÄ±ÅŸtÄ±rma |
| Recommendation Quality | >0.65 | ~0.70 | Genel kalite skoru |
| SDV Quality Score | >0.80 | ~0.85 | Sentetik veri kalitesi |

### Performans Benchmarks

**TRM (ARC-AGI-1):**
- Training: ~3 gÃ¼n (4x H100)
- Inference: ~100ms/puzzle
- Memory: ~8GB VRAM
- BaÅŸarÄ±: %45

**Gift Recommendation:**
- Training: ~6 saat (1x RTX 3090)
- Inference: ~50ms/recommendation
- Memory: ~4GB VRAM
- Quality Score: ~0.70


## YapÄ±landÄ±rma

### TRM Config (`config/cfg_pretrain.yaml`)
```yaml
data_paths: ['data/arc-aug-1000']
global_batch_size: 768
epochs: 100000
eval_interval: 10000

lr: 1e-4
lr_min_ratio: 1.0
lr_warmup_steps: 2000
weight_decay: 0.1

arch:
  L_layers: 2
  H_cycles: 3
  L_cycles: 4
  
ema: True
ema_rate: 0.999
```

### Gift Recommendation Config
```yaml
arch:
  hidden_size: 256
  L_layers: 2
  H_cycles: 3
  max_tool_calls_per_step: 3
  tool_selection_method: "confidence"

global_batch_size: 16
epochs: 150
lr: 1e-4

# Loss weights (optimized v5)
category_loss_weight: 0.25
tool_diversity_loss_weight: 0.20
tool_execution_loss_weight: 0.40
reward_loss_weight: 0.10
semantic_matching_loss_weight: 0.10

# Learning rates (component-specific)
user_profile_lr: 1.2e-4
category_matching_lr: 1.5e-4
tool_selection_lr: 2e-4
reward_prediction_lr: 2.5e-4

tools:
  available_tools:
    - "price_comparison"
    - "review_analysis"
    - "inventory_check"
    - "trend_analyzer"
    - "budget_optimizer"
```

### SDV Config (`config/sdv_config.yaml`)
```yaml
synthesizer:
  method: "gaussian"  # "gaussian", "ctgan", "tvae"
  
  ctgan:
    epochs: 300
    batch_size: 500
    
generation:
  num_synthetic_gifts: 500
  num_synthetic_users: 200
  
constraints:
  price_min: 10.0
  price_max: 500.0
  rating_min: 3.0
  rating_max: 5.0
```

## Performans ve Optimizasyon

### GPU KullanÄ±mÄ±
```python
# Otomatik device seÃ§imi
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Batch size ayarlama
# 8GB VRAM: batch_size=8
# 16GB VRAM: batch_size=16
# 24GB+ VRAM: batch_size=32
```

### Memory Optimization
```bash
# Gradient accumulation
python train_integrated_enhanced_model.py \
  --batch_size 8 --accumulation_steps 2

# Mixed precision (FP16)
python train_integrated_enhanced_model.py --fp16

# Gradient checkpointing
python train_integrated_enhanced_model.py --gradient_checkpointing
```

### Distributed Training
```bash
# Multi-GPU (4 GPU)
torchrun --nproc-per-node 4 train_integrated_enhanced_model.py

# Multi-node (2 nodes, 4 GPU each)
torchrun --nproc-per-node 4 --nnodes 2 \
  --node_rank 0 --master_addr "192.168.1.1" \
  train_integrated_enhanced_model.py
```

### Profiling
```bash
# PyTorch profiler
python train_integrated_enhanced_model.py --profile

# Memory profiling
python -m memory_profiler train_integrated_enhanced_model.py
```


## Sorun Giderme

### CUDA Out of Memory
```bash
# Ã‡Ã¶zÃ¼m 1: Batch size kÃ¼Ã§Ã¼lt
python train_integrated_enhanced_model.py --batch_size 8

# Ã‡Ã¶zÃ¼m 2: Gradient accumulation
python train_integrated_enhanced_model.py --batch_size 8 --accumulation_steps 4

# Ã‡Ã¶zÃ¼m 3: Gradient checkpointing
python train_integrated_enhanced_model.py --gradient_checkpointing

# Ã‡Ã¶zÃ¼m 4: CPU'da Ã§alÄ±ÅŸtÄ±r
CUDA_VISIBLE_DEVICES="" python train_integrated_enhanced_model.py
```

### SDV Kurulum HatasÄ±
```bash
# Python sÃ¼rÃ¼mÃ¼ kontrol (3.8+ gerekli)
python --version

# pip gÃ¼ncelle
pip install --upgrade pip

# SDV tekrar kur
pip uninstall sdv
pip install sdv>=1.0.0

# Conda ile kur (alternatif)
conda install -c conda-forge sdv
```

### Training Ã‡ok YavaÅŸ
```bash
# Ã‡Ã¶zÃ¼m 1: Epoch sayÄ±sÄ±nÄ± azalt
python train_integrated_enhanced_model.py --epochs 100

# Ã‡Ã¶zÃ¼m 2: Eval interval artÄ±r
python train_integrated_enhanced_model.py --eval_interval 10

# Ã‡Ã¶zÃ¼m 3: Batch size artÄ±r (GPU varsa)
python train_integrated_enhanced_model.py --batch_size 32

# Ã‡Ã¶zÃ¼m 4: DataLoader workers artÄ±r
python train_integrated_enhanced_model.py --num_workers 4
```

### Import Errors
```bash
# ModuleNotFoundError: No module named 'sdv'
pip install sdv pandas

# ModuleNotFoundError: No module named 'adam_atan2'
pip install --no-cache-dir --no-build-isolation adam-atan2

# ModuleNotFoundError: No module named 'models'
export PYTHONPATH="${PYTHONPATH}:$(pwd)"
```

### Checkpoint YÃ¼kleme HatasÄ±
```bash
# RuntimeError: Error(s) in loading state_dict
# Ã‡Ã¶zÃ¼m: strict=False kullan
checkpoint = torch.load(path, map_location=device)
model.load_state_dict(checkpoint['model_state_dict'], strict=False)
```

### Veri BulunamadÄ±
```bash
# FileNotFoundError: data/realistic_gift_catalog.json
python create_gift_data.py

# FileNotFoundError: data/arc1concept-aug-1000
python -m dataset.build_arc_dataset --output-dir data/arc1concept-aug-1000
```

## DokÃ¼mantasyon

### Ana DokÃ¼mantasyon
- [README.md](README.md) - Bu dosya (genel bakÄ±ÅŸ)
- [QUICK_START.md](QUICK_START.md) - HÄ±zlÄ± baÅŸlangÄ±Ã§ kÄ±lavuzu
- [LICENSE](LICENSE) - MIT lisansÄ±

### SDV DokÃ¼mantasyonu
- [SDV_README.md](SDV_README.md) - SDV hÄ±zlÄ± baÅŸlangÄ±Ã§
- [SDV_KULLANIM_KILAVUZU.md](SDV_KULLANIM_KILAVUZU.md) - DetaylÄ± TÃ¼rkÃ§e kÄ±lavuz
- [SDV_DOSYA_YAPISI.md](SDV_DOSYA_YAPISI.md) - Dosya yapÄ±sÄ± ve Ã¶zet

### Scraping DokÃ¼mantasyonu
- [scraping/README.md](scraping/README.md) - Web scraping kÄ±lavuzu

### Harici Kaynaklar
- [TRM Paper](https://arxiv.org/abs/2510.04871) - Orijinal makale
- [HRM Paper](https://arxiv.org/abs/2506.21734) - HRM makalesi
- [SDV Docs](https://docs.sdv.dev/) - SDV resmi dokÃ¼mantasyonu
- [PyTorch Docs](https://pytorch.org/docs/) - PyTorch dokÃ¼mantasyonu


## KullanÄ±m SenaryolarÄ±

### Senaryo 1: ARC-AGI Benchmark
```bash
# 1. Veri hazÄ±rla
python -m dataset.build_arc_dataset \
  --output-dir data/arc1concept-aug-1000

# 2. Model eÄŸit
torchrun --nproc-per-node 4 pretrain.py \
  arch=trm data_paths="[data/arc1concept-aug-1000]"

# 3. DeÄŸerlendir
python evaluate_arc.py \
  --checkpoint checkpoints/arc1concept/best.pt
```

### Senaryo 2: Hediye Ã–nerisi (SÄ±fÄ±rdan)
```bash
# 1. GerÃ§ek veri oluÅŸtur
python create_gift_data.py

# 2. Sentetik veri Ã¼ret
python sdv_advanced_generator.py

# 3. Veriyi birleÅŸtir
python merge_datasets.py

# 4. Model eÄŸit
python train_integrated_enhanced_model.py --epochs 150

# 5. Test et
python test_comprehensive_improvements.py

# 6. Fine-tune
python finetune_category_diversity.py
```

### Senaryo 3: Web Scraping + Training
```bash
# 1. Web scraping
python run_pipeline_root.py

# 2. Scraped veriyi kullan
python generate_fully_learned_synthetic.py

# 3. Model eÄŸit
python train_integrated_enhanced_model.py \
  --data-path data/fully_learned_synthetic_gifts.json

# 4. DeÄŸerlendir
python test_user_scenarios.py
```

### Senaryo 4: Checkpoint'ten Devam
```bash
# 1. En iyi modeli yÃ¼kle
python train_integrated_enhanced_model.py \
  --resume checkpoints/integrated_enhanced/integrated_enhanced_best.pt \
  --epochs 200

# 2. FarklÄ± learning rate ile devam
python train_integrated_enhanced_model.py \
  --resume checkpoints/integrated_enhanced/integrated_enhanced_best.pt \
  --learning_rate 5e-5 \
  --epochs 50
```

### Senaryo 5: Ã–zel Veri Seti
```bash
# 1. Kendi verinizi hazÄ±rlayÄ±n
# Format: data/my_custom_dataset.json
# {
#   "gifts": [...],
#   "metadata": {...}
# }

# 2. Config oluÅŸturun
# config/my_custom_config.yaml

# 3. EÄŸitin
python train_integrated_enhanced_model.py \
  --config config/my_custom_config.yaml \
  --data-path data/my_custom_dataset.json
```

## Ã–ne Ã‡Ä±kan Ã–zellikler

### TRM Ã–zellikleri
- âœ… **7M parametre** ile bÃ¼yÃ¼k modellere rakip performans
- âœ… **Recursive reasoning** - kendini iyileÅŸtiren model
- âœ… **Minimal overfitting** - kÃ¼Ã§Ã¼k veri setlerinde bile baÅŸarÄ±lÄ±
- âœ… **Multi-task** - ARC-AGI, Sudoku, Maze desteÄŸi
- âœ… **EMA** - Exponential Moving Average ile stabil eÄŸitim
- âœ… **Distributed training** - Multi-GPU/Multi-node desteÄŸi
- âœ… **Hydra config** - Esnek yapÄ±landÄ±rma sistemi

### Gift Recommendation Ã–zellikleri
- âœ… **Tool-enhanced** - 5 akÄ±llÄ± araÃ§ ile zenginleÅŸtirilmiÅŸ
- âœ… **Curriculum learning** - 4 aÅŸamalÄ± progressif Ã¶ÄŸrenme
- âœ… **SDV integration** - 3 farklÄ± sentetik veri yÃ¶ntemi
- âœ… **Web scraping** - 4 TÃ¼rk e-ticaret sitesi desteÄŸi
- âœ… **Integrated Enhanced TRM** - Ã‡ok bileÅŸenli geliÅŸmiÅŸ model
- âœ… **25+ test suite** - KapsamlÄ± test coverage
- âœ… **Checkpoint management** - Save/load/resume desteÄŸi
- âœ… **Fine-tuning** - Kategori Ã§eÅŸitliliÄŸi optimizasyonu
- âœ… **Real-time feedback** - AraÃ§ sonuÃ§larÄ±nÄ± modele geri bildirim
- âœ… **Multi-component reward** - 6 farklÄ± loss bileÅŸeni
- âœ… **Gradient accumulation** - BÃ¼yÃ¼k batch size simÃ¼lasyonu
- âœ… **Learning rate scheduling** - Otomatik LR ayarlama
- âœ… **Early stopping** - Overfitting Ã¶nleme


## Proje Ä°statistikleri

### Kod Ä°statistikleri

| BileÅŸen | Dosya SayÄ±sÄ± | SatÄ±r SayÄ±sÄ± | AÃ§Ä±klama |
|---------|--------------|--------------|----------|
| **Models** | 20+ | 5,000+ | TRM, RL, Tools |
| **Tests** | 5 | 2,000+ | KapsamlÄ± test suite |
| **Configs** | 7 | 500+ | YAML yapÄ±landÄ±rma |
| **Scripts** | 15+ | 3,000+ | Training, data gen |
| **Docs** | 5 | 2,000+ | TÃ¼rkÃ§e dokÃ¼mantasyon |
| **Scraping** | 10+ | 1,500+ | Web scraping |
| **Utils** | 5+ | 500+ | YardÄ±mcÄ± fonksiyonlar |
| **TOPLAM** | **65+** | **14,500+** | TÃ¼m proje |

### Model Ä°statistikleri

**TRM:**
- Parametre: 7M
- Layers: 2 (L) + 2 (H)
- Cycles: 3 (H) + 4 (L)
- Embedding dim: 256
- Attention heads: 8

**Integrated Enhanced TRM:**
- Parametre: ~2.3M
- Components: 6 (user, category, tool, reward, fusion, encoder)
- Tools: 5
- Categories: 15+
- Hidden dim: 128-256

### Veri Ä°statistikleri

| Veri KaynaÄŸÄ± | ÃœrÃ¼n SayÄ±sÄ± | KullanÄ±cÄ± | Kalite |
|--------------|-------------|-----------|--------|
| GerÃ§ek | 30 | 8 | Referans |
| SDV Basic | 200 | - | Orta |
| SDV Advanced | 300 | 150 | YÃ¼ksek |
| Fully Learned | 500 | 300 | Ã‡ok YÃ¼ksek |
| Web Scraped | 1000+ | - | GerÃ§ek |

### Test Coverage

- **Unit Tests**: 25+ test
- **Integration Tests**: 10+ test
- **End-to-End Tests**: 5+ senaryo
- **Coverage**: ~85%

## Yol HaritasÄ±

### âœ… Tamamlanan (v2.0)
- [x] TRM temel implementasyonu
- [x] ARC-AGI, Sudoku, Maze desteÄŸi
- [x] Tool-enhanced architecture
- [x] Integrated Enhanced TRM
- [x] SDV sentetik veri Ã¼retimi (3 yÃ¶ntem)
- [x] Web scraping pipeline (4 site)
- [x] Curriculum learning (4 stage)
- [x] KapsamlÄ± test suite (25+ test)
- [x] Fine-tuning desteÄŸi
- [x] Checkpoint management
- [x] TÃ¼rkÃ§e dokÃ¼mantasyon
- [x] Gradient accumulation
- [x] Learning rate scheduling
- [x] Early stopping

### ğŸ”„ Devam Eden (v2.1)
- [ ] Daha fazla e-ticaret sitesi (N11, GittiGidiyor)
- [ ] GeliÅŸmiÅŸ tool parametreleri (dynamic ranges)
- [ ] Multi-modal input (resim + metin)
- [ ] Real-time recommendation API
- [ ] Model compression (pruning, quantization)
- [ ] A/B testing framework

### ğŸ”® Gelecek Planlar (v3.0)
- [ ] Transformer-based TRM variant
- [ ] Federated learning desteÄŸi
- [ ] Mobile deployment (ONNX, TFLite)
- [ ] Web UI dashboard (React + FastAPI)
- [ ] User feedback loop
- [ ] Multi-language support (EN, TR, DE)
- [ ] Cloud deployment (AWS, GCP, Azure)
- [ ] Monitoring & logging (Prometheus, Grafana)


## Ä°puÃ§larÄ± ve En Ä°yi Pratikler

### TRM EÄŸitimi Ä°Ã§in

1. **EMA KullanÄ±n**
   ```bash
   python pretrain.py ema=True ema_rate=0.999
   ```
   - Daha stabil sonuÃ§lar
   - Overfitting'i azaltÄ±r
   - %2-3 performans artÄ±ÅŸÄ±

2. **Learning Rate Warmup**
   ```yaml
   lr_warmup_steps: 2000  # Ä°lk 2000 adÄ±m
   ```
   - BaÅŸlangÄ±Ã§ta dÃ¼ÅŸÃ¼k LR
   - Kademeli artÄ±ÅŸ
   - Daha iyi convergence

3. **Batch Size Ayarlama**
   - 8GB VRAM: batch_size=256
   - 16GB VRAM: batch_size=512
   - 24GB+ VRAM: batch_size=768

4. **Eval Interval**
   ```yaml
   eval_interval: 10000  # Her 10K step
   ```
   - Ã‡ok sÄ±k: YavaÅŸ training
   - Ã‡ok seyrek: Overfitting riski

### Hediye Ã–nerisi Ä°Ã§in

1. **Veri Ã‡eÅŸitliliÄŸi**
   ```bash
   # GerÃ§ek + Sentetik karÄ±ÅŸÄ±mÄ±
   python merge_datasets.py \
     --real data/realistic_gift_catalog.json \
     --synthetic data/fully_learned_synthetic_gifts.json \
     --ratio 0.3  # %30 gerÃ§ek, %70 sentetik
   ```

2. **Curriculum Learning**
   - Stage 0 (Epoch 0-10): Tek araÃ§
   - Stage 1 (Epoch 10-25): Ä°ki araÃ§
   - Stage 2 (Epoch 25-45): ÃœÃ§ araÃ§
   - Stage 3 (Epoch 45+): TÃ¼m araÃ§lar

3. **Tool Feedback**
   ```python
   # AraÃ§ sonuÃ§larÄ±nÄ± modele geri bildirin
   tool_results = execute_tools(selected_tools)
   encoded_results = tool_encoder(tool_results)
   carry = update_carry(carry, encoded_results)
   ```

4. **Fine-Tuning**
   ```bash
   # Ä°lk eÄŸitimden sonra
   python finetune_category_diversity.py
   ```
   - Kategori Ã§eÅŸitliliÄŸini artÄ±rÄ±r
   - %5-10 performans artÄ±ÅŸÄ±

5. **Test SÄ±k**
   ```bash
   # Her deÄŸiÅŸiklikten sonra
   python test_tool_integration.py
   python test_comprehensive_improvements.py
   ```

### SDV KullanÄ±mÄ± Ä°Ã§in

1. **KÃ¼Ã§Ã¼k BaÅŸlayÄ±n**
   ```python
   # Ä°lk denemede az Ã¶rnek
   synthetic_df = synthesizer.sample(num_rows=50)
   ```

2. **Kalite Kontrol**
   ```python
   quality_report = evaluate_quality(real_data, synthetic_data)
   score = quality_report.get_score()
   
   if score < 0.80:
       print("âš ï¸ DÃ¼ÅŸÃ¼k kalite, parametreleri ayarlayÄ±n")
   ```

3. **YÃ¶ntem SeÃ§imi**
   - **Gaussian Copula**: HÄ±zlÄ± prototipleme
   - **CTGAN**: Ãœretim ortamÄ±
   - **TVAE**: Dengeli seÃ§im

4. **Constraint KullanÄ±n**
   ```python
   constraints = [
       Inequality(low='discount_price', high='price'),
       Range(column='rating', low=1.0, high=5.0)
   ]
   synthesizer.add_constraints(constraints)
   ```

### Debugging Ä°puÃ§larÄ±

1. **Gradient Checking**
   ```python
   # NaN kontrolÃ¼
   for name, param in model.named_parameters():
       if param.grad is not None:
           if torch.isnan(param.grad).any():
               print(f"NaN gradient in {name}")
   ```

2. **Loss Monitoring**
   ```python
   # Loss bileÅŸenlerini izleyin
   print(f"Total: {total_loss:.4f}")
   print(f"Category: {category_loss:.4f}")
   print(f"Tool: {tool_loss:.4f}")
   ```

3. **Memory Profiling**
   ```bash
   # GPU memory kullanÄ±mÄ±
   nvidia-smi -l 1
   
   # PyTorch memory
   print(torch.cuda.memory_allocated() / 1e9, "GB")
   ```


## KatkÄ±da Bulunma

KatkÄ±larÄ±nÄ±zÄ± bekliyoruz! ğŸ‰

### KatkÄ± SÃ¼reci

1. **Fork** yapÄ±n
2. **Feature branch** oluÅŸturun
   ```bash
   git checkout -b feature/amazing-feature
   ```
3. **Commit** yapÄ±n
   ```bash
   git commit -m 'feat: Add amazing feature'
   ```
4. **Push** edin
   ```bash
   git push origin feature/amazing-feature
   ```
5. **Pull Request** aÃ§Ä±n

### Commit Mesaj FormatÄ±

```
<type>(<scope>): <subject>

<body>

<footer>
```

**Types:**
- `feat`: Yeni Ã¶zellik
- `fix`: Bug fix
- `docs`: DokÃ¼mantasyon
- `style`: Formatting
- `refactor`: Code refactoring
- `test`: Test ekleme
- `chore`: Maintenance

**Ã–rnek:**
```
feat(tools): Add budget_optimizer tool

- Implement budget optimization algorithm
- Add tests for budget_optimizer
- Update documentation

Closes #123
```

### Kod StandartlarÄ±

- **Python**: PEP 8
- **Docstrings**: Google style
- **Type hints**: KullanÄ±n
- **Tests**: Her yeni Ã¶zellik iÃ§in test yazÄ±n

### Test Gereksinimleri

```bash
# TÃ¼m testleri Ã§alÄ±ÅŸtÄ±rÄ±n
python test_tool_integration.py
python test_comprehensive_improvements.py
python test_active_tool_usage.py

# Yeni test ekleyin
# tests/test_my_feature.py
```

## Lisans

Bu proje **MIT lisansÄ±** altÄ±nda lisanslanmÄ±ÅŸtÄ±r.

```
MIT License

Copyright (c) 2025 TinyRecursiveModels Contributors

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
```

Detaylar iÃ§in [LICENSE](LICENSE) dosyasÄ±na bakÄ±n.

## Ä°letiÅŸim ve Destek

### Destek KanallarÄ±

- **GitHub Issues**: Bug raporlarÄ± ve Ã¶zellik istekleri
- **GitHub Discussions**: Genel sorular ve tartÄ±ÅŸmalar
- **Email**: [KorunmuÅŸtur]

### SÄ±k Sorulan Sorular (FAQ)

**S: TRM'yi kendi veri setimde kullanabilir miyim?**
C: Evet! `dataset/build_arc_dataset.py` dosyasÄ±nÄ± referans alarak kendi veri setinizi hazÄ±rlayabilirsiniz.

**S: GPU olmadan eÄŸitim yapabilir miyim?**
C: Evet, ancak Ã§ok yavaÅŸ olacaktÄ±r. CPU'da eÄŸitim iÃ§in batch size'Ä± kÃ¼Ã§Ã¼ltÃ¼n.

**S: Hediye Ã¶nerisi sistemini baÅŸka diller iÃ§in kullanabilir miyim?**
C: Evet! Veri setini ve kategori isimlerini deÄŸiÅŸtirerek kullanabilirsiniz.

**S: SDV kalite skoru dÃ¼ÅŸÃ¼k Ã§Ä±kÄ±yor, ne yapmalÄ±yÄ±m?**
C: Daha fazla gerÃ§ek veri toplayÄ±n, CTGAN kullanÄ±n, epoch sayÄ±sÄ±nÄ± artÄ±rÄ±n.

**S: Checkpoint dosyasÄ± Ã§ok bÃ¼yÃ¼k, nasÄ±l kÃ¼Ã§Ã¼ltebilirim?**
C: Sadece model weights'i kaydedin, optimizer state'i kaydetmeyin.


## TeÅŸekkÃ¼rler

Bu proje ÅŸu Ã§alÄ±ÅŸmalara dayanmaktadÄ±r:

### Akademik Ã‡alÄ±ÅŸmalar

#### TRM (Tiny Recursion Model)
```bibtex
@misc{jolicoeurmartineau2025morerecursivereasoningtiny,
      title={Less is More: Recursive Reasoning with Tiny Networks}, 
      author={Alexia Jolicoeur-Martineau},
      year={2025},
      eprint={2510.04871},
      archivePrefix={arXiv},
      primaryClass={cs.LG},
      url={https://arxiv.org/abs/2510.04871}, 
}
```

#### HRM (Hierarchical Reasoning Model)
```bibtex
@misc{wang2025hierarchicalreasoningmodel,
      title={Hierarchical Reasoning Model}, 
      author={Guan Wang and Jin Li and Yuhao Sun and Xing Chen and 
              Changling Liu and Yue Wu and Meng Lu and Sen Song and 
              Yasin Abbasi Yadkori},
      year={2025},
      eprint={2506.21734},
      archivePrefix={arXiv},
      primaryClass={cs.AI},
      url={https://arxiv.org/abs/2506.21734}, 
}
```

### Kod KaynaklarÄ±

- [HRM Code](https://github.com/sapientinc/HRM) - Hierarchical Reasoning Model
- [HRM Analysis](https://github.com/arcprize/hierarchical-reasoning-model-analysis) - HRM analizi
- [SDV](https://github.com/sdv-dev/SDV) - Synthetic Data Vault
- [PyTorch](https://github.com/pytorch/pytorch) - Deep learning framework

### KÃ¼tÃ¼phaneler ve AraÃ§lar

- **PyTorch**: Deep learning framework
- **SDV**: Sentetik veri Ã¼retimi
- **Hydra**: YapÄ±landÄ±rma yÃ¶netimi
- **Weights & Biases**: Experiment tracking
- **Pydantic**: Data validation
- **NumPy**: Numerical computing
- **Pandas**: Data manipulation

### Veri KaynaklarÄ±

- **ARC-AGI**: Abstraction and Reasoning Corpus
- **Trendyol**: E-ticaret verisi
- **Hepsiburada**: E-ticaret verisi
- **Ã‡iÃ§ek Sepeti**: Hediye verisi
- **Cimri**: Fiyat karÅŸÄ±laÅŸtÄ±rma

### Topluluk

Projeye katkÄ±da bulunan herkese teÅŸekkÃ¼rler! ğŸ™

---

## ğŸ‰ BaÅŸarÄ±lar!

Projeyi kullandÄ±ÄŸÄ±nÄ±z iÃ§in teÅŸekkÃ¼rler! 

### HÄ±zlÄ± Linkler

- ğŸ“– [DokÃ¼mantasyon](#dokÃ¼mantasyon)
- ğŸš€ [HÄ±zlÄ± BaÅŸlangÄ±Ã§](#hÄ±zlÄ±-baÅŸlangÄ±Ã§)
- ğŸ§ª [Test](#test-ve-deÄŸerlendirme)
- ğŸ’¡ [Ä°puÃ§larÄ±](#ipuÃ§larÄ±-ve-en-iyi-pratikler)
- ğŸ› [Sorun Giderme](#sorun-giderme)

### Ä°statistikler

![GitHub stars](https://img.shields.io/github/stars/username/TinyRecursiveModels?style=social)
![GitHub forks](https://img.shields.io/github/forks/username/TinyRecursiveModels?style=social)
![GitHub issues](https://img.shields.io/github/issues/username/TinyRecursiveModels)
![GitHub license](https://img.shields.io/github/license/username/TinyRecursiveModels)

### Teknolojiler

![Python](https://img.shields.io/badge/Python-3.10+-blue.svg)
![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-red.svg)
![CUDA](https://img.shields.io/badge/CUDA-12.6+-green.svg)
![License](https://img.shields.io/badge/License-MIT-yellow.svg)

---

<p align="center">
  <strong>Happy Training! ğŸš€</strong><br>
  <sub>Son gÃ¼ncelleme: 2025 | Versiyon: 2.0 | Dil: TÃ¼rkÃ§e</sub>
</p>

<p align="center">
  Made with â¤ï¸ by TinyRecursiveModels Contributors
</p>
