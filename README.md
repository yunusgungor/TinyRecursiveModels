# ğŸ TRM-Based AI Gift Recommendation System

**Tiny Recursive Model (TRM) tabanlÄ±, Tool-Augmented ve Reinforcement Learning ile gÃ¼Ã§lendirilmiÅŸ akÄ±llÄ± hediye Ã¶neri sistemi**

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![PyTorch](https://img.shields.io/badge/PyTorch-2.0+-ee4c2c.svg)](https://pytorch.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

---

## ğŸ“‹ Ä°Ã§indekiler

- [Genel BakÄ±ÅŸ](#-genel-bakÄ±ÅŸ)
- [Temel Ã–zellikler](#-temel-Ã¶zellikler)
- [Mimari](#-mimari)
- [Kurulum](#-kurulum)
- [Veri Pipeline](#-veri-pipeline)
- [Model EÄŸitimi](#-model-eÄŸitimi)
- [KullanÄ±m](#-kullanÄ±m)
- [Proje YapÄ±sÄ±](#-proje-yapÄ±sÄ±)
- [KatkÄ±da Bulunma](#-katkÄ±da-bulunma)
- [Lisans](#-lisans)

---

## ğŸ¯ Genel BakÄ±ÅŸ

Bu proje, **Tiny Recursive Model (TRM)** mimarisini temel alarak geliÅŸtirilmiÅŸ, **Reinforcement Learning (RL)** ve **Tool-Augmented Reasoning** ile gÃ¼Ã§lendirilmiÅŸ bir hediye Ã¶neri sistemidir. Sistem, gerÃ§ek e-ticaret sitelerinden toplanan verilerle eÄŸitilir ve kullanÄ±cÄ± profiline gÃ¶re kiÅŸiselleÅŸtirilmiÅŸ hediye Ã¶nerileri sunar.

### ğŸŒŸ Neden Bu Proje?

- **ğŸ§  AkÄ±llÄ± Reasoning**: TRM'nin recursive reasoning yetenekleri ile derin analiz
- **ğŸ”§ Tool Integration**: 5 farklÄ± tool ile zenginleÅŸtirilmiÅŸ karar verme
- **ğŸ® RL Training**: PPO-style reinforcement learning ile optimize edilmiÅŸ Ã¶neriler
- **ğŸ“Š GerÃ§ek Veri**: TÃ¼rkiye'nin Ã¶nde gelen e-ticaret sitelerinden toplanan gerÃ§ek Ã¼rÃ¼n verileri
- **ğŸ¤– AI Enhancement**: Gemini API ile zenginleÅŸtirilmiÅŸ Ã¼rÃ¼n metadata'sÄ±
- **ğŸ² Synthetic Data**: SDV ile oluÅŸturulan gerÃ§ekÃ§i kullanÄ±cÄ± senaryolarÄ±

---

## âœ¨ Temel Ã–zellikler

### ğŸ” 1. Web Scraping Pipeline

GerÃ§ek e-ticaret sitelerinden otomatik veri toplama:

- **Desteklenen Siteler**: Ã‡iÃ§ek Sepeti, Hepsiburada, Trendyol
- **Anti-Bot Protection**: Rate limiting, user agent rotation, CAPTCHA detection
- **Veri Validasyonu**: Pydantic ile gÃ¼Ã§lÃ¼ veri doÄŸrulama
- **AI Enhancement**: Gemini API ile Ã¼rÃ¼n verilerini zenginleÅŸtirme

```bash
# Scraping pipeline'Ä± Ã§alÄ±ÅŸtÄ±r
python scraping/scripts/scraping.py --website trendyol --max-products 500
```

### ğŸ² 2. Synthetic Data Generation

SDV (Synthetic Data Vault) kullanarak gerÃ§ekÃ§i kullanÄ±cÄ± senaryolarÄ± oluÅŸturma:

- **Dinamik Kategori Ã‡Ä±karÄ±mÄ±**: GerÃ§ek veriden otomatik kategori tespiti
- **GerÃ§ekÃ§i Profiller**: YaÅŸ, hobi, bÃ¼tÃ§e, iliÅŸki, Ã¶zel gÃ¼n kombinasyonlarÄ±
- **Ã‡eÅŸitlilik**: 100+ farklÄ± kullanÄ±cÄ± senaryosu

### ğŸ§  3. Integrated Enhanced TRM Model

TÃ¼m geliÅŸtirmeler model mimarisine entegre edilmiÅŸ:

#### a) Enhanced User Profiling
- **Hobby Embeddings**: KullanÄ±cÄ± hobilerinin semantik temsili
- **Preference Encoding**: KiÅŸilik Ã¶zelliklerinin vektÃ¶r temsili
- **Occasion Awareness**: Ã–zel gÃ¼nlere gÃ¶re uyarlama
- **Age & Budget Encoding**: YaÅŸ ve bÃ¼tÃ§e bilgisinin sÃ¼rekli kodlamasÄ±

#### b) Enhanced Category Matching
- **Semantic Matching**: Ã‡ok katmanlÄ± semantik eÅŸleÅŸtirme aÄŸÄ±
- **Category Attention**: Multi-head attention ile kategori skorlama
- **Dynamic Categories**: Veri setinden dinamik kategori yÃ¼kleme

#### c) Enhanced Tool Selection
- **Context-Aware Selection**: KullanÄ±cÄ± baÄŸlamÄ±na gÃ¶re tool seÃ§imi
- **Tool Diversity**: Ã‡eÅŸitli tool kullanÄ±mÄ±nÄ± teÅŸvik eden mekanizma
- **Parameter Generation**: Her tool iÃ§in otomatik parametre Ã¼retimi

#### d) Enhanced Reward Prediction
- **Multi-Component Rewards**: 7 farklÄ± reward bileÅŸeni
  - Category match
  - Budget compatibility
  - Hobby alignment
  - Occasion appropriateness
  - Age appropriateness
  - Quality score
  - Diversity bonus
- **Reward Fusion**: Ã‡ok katmanlÄ± fusion network

### ğŸ”§ 4. Tool System

5 farklÄ± tool ile zenginleÅŸtirilmiÅŸ karar verme:

| Tool | AÃ§Ä±klama | KullanÄ±m Senaryosu |
|------|----------|-------------------|
| **Price Comparison** | Fiyat karÅŸÄ±laÅŸtÄ±rma ve bÃ¼tÃ§e filtreleme | BÃ¼tÃ§eye uygun hediye bulma |
| **Inventory Check** | Stok durumu kontrolÃ¼ | Mevcut Ã¼rÃ¼nleri belirleme |
| **Review Analysis** | ÃœrÃ¼n yorumlarÄ±nÄ± analiz etme | Kaliteli Ã¼rÃ¼nleri seÃ§me |
| **Trend Analysis** | Trend ve popÃ¼lerlik analizi | PopÃ¼ler hediyeleri bulma |
| **Budget Optimizer** | BÃ¼tÃ§e optimizasyonu | BÃ¼tÃ§eyi en iyi ÅŸekilde kullanma |

### ğŸ® 5. Reinforcement Learning

PPO-style training ile optimize edilmiÅŸ Ã¶neriler:

- **Experience Replay**: GeÃ§miÅŸ deneyimlerden Ã¶ÄŸrenme
- **Value Estimation**: Durum deÄŸeri tahmini
- **Policy Optimization**: PPO clip ratio ile policy gÃ¼ncelleme
- **Entropy Regularization**: KeÅŸif-sÃ¶mÃ¼rÃ¼ dengesi

---

## ğŸ—ï¸ Mimari

### Sistem Mimarisi

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     TRM Gift Recommendation System               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                        Data Pipeline                             â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  1. Web Scraping (Ã‡iÃ§ek Sepeti, Hepsiburada, Trendyol)         â”‚
â”‚  2. AI Enhancement (Gemini API)                                  â”‚
â”‚  3. Synthetic Data Generation (SDV)                              â”‚
â”‚  4. Dataset Creation (Gift Catalog + User Scenarios)            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                   Integrated Enhanced TRM Model                  â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ User Profiling  â”‚  â”‚ Category Match  â”‚  â”‚ Tool Selection  â”‚ â”‚
â”‚  â”‚                 â”‚  â”‚                 â”‚  â”‚                 â”‚ â”‚
â”‚  â”‚ â€¢ Hobby Embed   â”‚  â”‚ â€¢ Semantic      â”‚  â”‚ â€¢ Context-Aware â”‚ â”‚
â”‚  â”‚ â€¢ Preference    â”‚  â”‚ â€¢ Attention     â”‚  â”‚ â€¢ Diversity     â”‚ â”‚
â”‚  â”‚ â€¢ Occasion      â”‚  â”‚ â€¢ Scoring       â”‚  â”‚ â€¢ Parameters    â”‚ â”‚
â”‚  â”‚ â€¢ Age/Budget    â”‚  â”‚                 â”‚  â”‚                 â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                              â”‚                                   â”‚
â”‚                              â–¼                                   â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚           Cross-Modal Fusion & RL Components             â”‚  â”‚
â”‚  â”‚                                                           â”‚  â”‚
â”‚  â”‚  â€¢ Multi-head Attention Layers                           â”‚  â”‚
â”‚  â”‚  â€¢ Policy Head (Action Probabilities)                    â”‚  â”‚
â”‚  â”‚  â€¢ Value Head (State Value Estimation)                   â”‚  â”‚
â”‚  â”‚  â€¢ Reward Predictor (Multi-Component)                    â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Tool System                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  Price Comparison â”‚ Inventory Check â”‚ Review Analysis           â”‚
â”‚  Trend Analysis   â”‚ Budget Optimizer                            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Gift Recommendations                          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Model DetaylarÄ±

**Integrated Enhanced TRM** modeli ÅŸu bileÅŸenlerden oluÅŸur:

1. **Base TRM**: Recursive reasoning iÃ§in temel mimari
2. **RL Heads**: Policy, value ve reward prediction heads
3. **Enhanced Components**: User profiling, category matching, tool selection
4. **Cross-Modal Fusion**: User-gift-tool etkileÅŸimlerini birleÅŸtiren attention layers

**Model Parametreleri**:
- Hidden Size: 512
- Attention Heads: 8
- L Layers: 3
- H Layers: 3
- H Cycles: 2
- L Cycles: 3
- Action Space: 50 (max gifts)
- Max Recommendations: 3

---

## ğŸš€ Kurulum

### Gereksinimler

- Python 3.8+
- PyTorch 2.0+
- CUDA 11.8+ (GPU eÄŸitimi iÃ§in)
- 16GB+ RAM
- 10GB+ Disk alanÄ±

### AdÄ±m 1: Repository'yi KlonlayÄ±n

```bash
git clone https://github.com/yourusername/trm-gift-recommendation.git
cd trm-gift-recommendation
```

### AdÄ±m 2: Sanal Ortam OluÅŸturun

```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# veya
venv\Scripts\activate  # Windows
```

### AdÄ±m 3: BaÄŸÄ±mlÄ±lÄ±klarÄ± YÃ¼kleyin

```bash
# Ana baÄŸÄ±mlÄ±lÄ±klar
pip install -r requirements.txt

# Scraping iÃ§in ek baÄŸÄ±mlÄ±lÄ±klar
pip install -r scraping/requirements.txt

# Playwright browser kurulumu
playwright install chromium
```

### AdÄ±m 4: Environment Variables

Scraping iÃ§in Gemini API key'inizi ayarlayÄ±n:

```bash
cd scraping
cp .env.example .env
# .env dosyasÄ±nÄ± dÃ¼zenleyip GEMINI_API_KEY ekleyin
```

---

## ğŸ“Š Veri Pipeline

### 1. Web Scraping

GerÃ§ek e-ticaret sitelerinden veri toplama:

```bash
# Tek siteden scraping
python scraping/scripts/scraping.py --website trendyol --max-products 500

# TÃ¼m sitelerden scraping
python scraping/scripts/scraping.py --max-products 1000

# Test modu (hÄ±zlÄ± test)
python scraping/scripts/scraping.py --test
```

**Ã‡Ä±ktÄ±**: `data/scraped_gift_catalog.json`

### 2. Synthetic Data Generation

KullanÄ±cÄ± senaryolarÄ± oluÅŸturma:

```bash
# Scraping ile birlikte otomatik oluÅŸturulur
# Veya manuel test:
python scraping/scripts/test_scenario_generator.py
```

**Ã‡Ä±ktÄ±**: `data/user_scenarios.json`

### 3. Dataset YapÄ±sÄ±

#### Gift Catalog Format

```json
{
  "gifts": [
    {
      "id": "trendyol_0000",
      "name": "ÃœrÃ¼n AdÄ±",
      "category": "technology",
      "price": 299.90,
      "rating": 4.5,
      "tags": ["smart", "portable", "practical"],
      "age_range": [18, 65],
      "occasions": ["birthday", "christmas", "graduation"]
    }
  ],
  "metadata": {
    "total_gifts": 500,
    "categories": ["technology", "home", "beauty", "health", "kitchen"],
    "price_range": {"min": 10, "max": 50000, "avg": 1250}
  }
}
```

#### User Scenarios Format

```json
{
  "scenarios": [
    {
      "id": "scenario_0000",
      "profile": {
        "age": 35,
        "hobbies": ["technology", "gaming", "reading"],
        "relationship": "friend",
        "budget": 500,
        "occasion": "birthday",
        "preferences": ["practical", "modern", "innovative"]
      },
      "expected_categories": ["technology", "gaming"],
      "expected_tools": ["price_comparison", "review_analysis"]
    }
  ]
}
```

---

## ğŸ“ Model EÄŸitimi

### Pretrain (Temel EÄŸitim)

TRM modelini temel gÃ¶revler Ã¼zerinde eÄŸitme:

```bash
# ARC dataset ile pretrain
python pretrain.py \
  --data_paths data/arc-aug-1000 \
  --global_batch_size 768 \
  --epochs 100000 \
  --lr 1e-4 \
  --eval_interval 10000
```

### Fine-tune (Hediye Ã–nerisi iÃ§in)

Pretrain edilmiÅŸ modeli hediye Ã¶nerisi iÃ§in fine-tune etme:

```bash
# Gift recommendation iÃ§in fine-tune
python pretrain.py \
  --data_paths data/gift_recommendation \
  --load_checkpoint checkpoints/pretrained_model \
  --global_batch_size 256 \
  --epochs 50000 \
  --lr 5e-5
```

### EÄŸitim Parametreleri

| Parametre | AÃ§Ä±klama | VarsayÄ±lan |
|-----------|----------|------------|
| `global_batch_size` | Global batch size | 768 |
| `lr` | Learning rate | 1e-4 |
| `lr_min_ratio` | Minimum LR ratio | 1.0 |
| `lr_warmup_steps` | Warmup steps | 2000 |
| `weight_decay` | Weight decay | 0.1 |
| `beta1` | Adam beta1 | 0.9 |
| `beta2` | Adam beta2 | 0.95 |
| `ema` | Use EMA | False |
| `ema_rate` | EMA rate | 0.999 |

### Distributed Training

Ã‡oklu GPU ile eÄŸitim:

```bash
# 4 GPU ile eÄŸitim
torchrun --nproc_per_node=4 pretrain.py \
  --data_paths data/gift_recommendation \
  --global_batch_size 1024
```

---

## ğŸ’» KullanÄ±m

### 1. Model YÃ¼kleme

```python
from models.tools.integrated_enhanced_trm import IntegratedEnhancedTRM, create_integrated_enhanced_config

# Config oluÅŸtur
config = create_integrated_enhanced_config()

# Model yÃ¼kle
model = IntegratedEnhancedTRM(config)
model.load_state_dict(torch.load("checkpoints/best_model.pt"))
model.eval()
```

### 2. Hediye Ã–nerisi Alma

```python
from models.rl.environment import UserProfile, EnvironmentState, GiftItem

# KullanÄ±cÄ± profili oluÅŸtur
user = UserProfile(
    age=35,
    hobbies=["technology", "gaming"],
    relationship="friend",
    budget=500.0,
    occasion="birthday",
    personality_traits=["practical", "modern"]
)

# Mevcut hediyeler
gifts = [
    GiftItem("1", "Wireless Headphones", "technology", 450.0, 4.5, 
             ["wireless", "portable"], "Headphones", (16, 65), ["birthday"]),
    GiftItem("2", "Smart Watch", "technology", 800.0, 4.7,
             ["smart", "fitness"], "Watch", (18, 60), ["birthday"])
]

# Environment state oluÅŸtur
env_state = EnvironmentState(user, gifts, [], [], 0)

# Model ile Ã¶neri al
with torch.no_grad():
    carry = model.initial_carry({"inputs": torch.randn(50), 
                                 "puzzle_identifiers": torch.zeros(1, dtype=torch.long)})
    carry, rl_output, selected_tools = model.forward_with_enhancements(
        carry, env_state, gifts
    )
    
    # Action seÃ§
    action = model.select_action(rl_output["action_probs"], gifts, deterministic=True)
    
    print("Ã–nerilen Hediyeler:")
    for gift in action["selected_gifts"]:
        print(f"  - {gift.name} ({gift.price} TL)")
```

### 3. Tool KullanÄ±mÄ±

```python
from models.tools.tool_registry import ToolRegistry
from models.tools.gift_tools import GiftRecommendationTools

# Tool registry oluÅŸtur
registry = ToolRegistry()
gift_tools = GiftRecommendationTools()

# ToollarÄ± kaydet
for tool in gift_tools.get_all_tools():
    registry.register_tool(tool)

# Price comparison tool kullan
result = registry.call_tool_by_name(
    "price_comparison",
    gifts=gifts,
    budget=500.0
)

print(f"BÃ¼tÃ§eye uygun: {len(result.result['in_budget'])} Ã¼rÃ¼n")
print(f"BÃ¼tÃ§e dÄ±ÅŸÄ±: {len(result.result['over_budget'])} Ã¼rÃ¼n")
```

### 4. RL Training Loop

```python
# Experience toplama
experiences = []

for episode in range(num_episodes):
    env_state = create_random_environment()
    carry = model.initial_carry(batch)
    
    # Forward pass
    carry, rl_output, tool_calls = model.forward_with_tools(
        carry, env_state, available_gifts, max_tool_calls=2
    )
    
    # Action seÃ§
    action = model.select_action(rl_output["action_probs"], available_gifts)
    
    # Reward hesapla
    reward = calculate_reward(action, env_state)
    
    # Experience kaydet
    experience = {
        "state": env_state,
        "action": action,
        "reward": reward,
        "carry": carry,
        "env_state": env_state,
        "available_gifts": available_gifts,
        "log_prob": action["log_probs"],
        "value": rl_output["state_value"],
        "done": False
    }
    experiences.append(experience)

# RL loss hesapla ve optimize et
loss_dict = model.compute_rl_loss(experiences, gamma=0.99)
loss_dict["total_loss"].backward()
optimizer.step()
```

---

## ğŸ“ Proje YapÄ±sÄ±

```
trm-gift-recommendation/
â”œâ”€â”€ README.md                          # Bu dosya
â”œâ”€â”€ requirements.txt                   # Ana baÄŸÄ±mlÄ±lÄ±klar
â”œâ”€â”€ pretrain.py                        # EÄŸitim scripti
â”œâ”€â”€ puzzle_dataset.py                  # Dataset loader
â”‚
â”œâ”€â”€ config/                            # KonfigÃ¼rasyon dosyalarÄ±
â”‚   â”œâ”€â”€ cfg_pretrain.yaml             # Pretrain config
â”‚   â””â”€â”€ arch/                         # Model mimarisi configs
â”‚
â”œâ”€â”€ data/                              # Veri dosyalarÄ±
â”‚   â”œâ”€â”€ gift_catalog.json             # Hediye kataloÄŸu
â”‚   â”œâ”€â”€ user_scenarios.json           # KullanÄ±cÄ± senaryolarÄ±
â”‚   â”œâ”€â”€ fully_learned_synthetic_gifts.json
â”‚   â””â”€â”€ fully_learned_synthetic_users.json
â”‚
â”œâ”€â”€ dataset/                           # Dataset oluÅŸturma
â”‚   â”œâ”€â”€ build_arc_dataset.py         # ARC dataset builder
â”‚   â”œâ”€â”€ build_maze_dataset.py        # Maze dataset builder
â”‚   â”œâ”€â”€ build_sudoku_dataset.py      # Sudoku dataset builder
â”‚   â””â”€â”€ common.py                     # Ortak fonksiyonlar
â”‚
â”œâ”€â”€ models/                            # Model mimarileri
â”‚   â”œâ”€â”€ common.py                     # Ortak model bileÅŸenleri
â”‚   â”œâ”€â”€ layers.py                     # Custom layers
â”‚   â”œâ”€â”€ losses.py                     # Loss fonksiyonlarÄ±
â”‚   â”œâ”€â”€ ema.py                        # Exponential Moving Average
â”‚   â”‚
â”‚   â”œâ”€â”€ recursive_reasoning/          # TRM mimarisi
â”‚   â”‚   â””â”€â”€ trm.py                    # Tiny Recursive Model
â”‚   â”‚
â”‚   â”œâ”€â”€ rl/                           # RL bileÅŸenleri
â”‚   â”‚   â”œâ”€â”€ rl_trm.py                # RL-enhanced TRM
â”‚   â”‚   â””â”€â”€ environment.py           # RL environment
â”‚   â”‚
â”‚   â””â”€â”€ tools/                        # Tool system
â”‚       â”œâ”€â”€ tool_registry.py         # Tool registry
â”‚       â”œâ”€â”€ gift_tools.py            # Gift-specific tools
â”‚       â””â”€â”€ integrated_enhanced_trm.py  # Ana model
â”‚
â”œâ”€â”€ scraping/                          # Web scraping pipeline
â”‚   â”œâ”€â”€ README.md                     # Scraping dokÃ¼mantasyonu
â”‚   â”œâ”€â”€ requirements.txt              # Scraping baÄŸÄ±mlÄ±lÄ±klarÄ±
â”‚   â”œâ”€â”€ .env                          # Environment variables
â”‚   â”‚
â”‚   â”œâ”€â”€ config/                       # Scraping configs
â”‚   â”‚   â””â”€â”€ scraping_config.yaml
â”‚   â”‚
â”‚   â”œâ”€â”€ scrapers/                     # Web scrapers
â”‚   â”‚   â”œâ”€â”€ base_scraper.py
â”‚   â”‚   â”œâ”€â”€ ciceksepeti_scraper.py
â”‚   â”‚   â”œâ”€â”€ hepsiburada_scraper.py
â”‚   â”‚   â”œâ”€â”€ trendyol_scraper.py
â”‚   â”‚   â””â”€â”€ orchestrator.py
â”‚   â”‚
â”‚   â”œâ”€â”€ services/                     # Servisler
â”‚   â”‚   â”œâ”€â”€ gemini_service.py        # AI enhancement
â”‚   â”‚   â””â”€â”€ dataset_generator.py     # Dataset oluÅŸturma
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                        # YardÄ±mcÄ± araÃ§lar
â”‚   â”‚   â”œâ”€â”€ models.py                # Pydantic models
â”‚   â”‚   â”œâ”€â”€ validator.py             # Veri validasyonu
â”‚   â”‚   â”œâ”€â”€ rate_limiter.py          # Rate limiting
â”‚   â”‚   â”œâ”€â”€ anti_bot.py              # Anti-bot protection
â”‚   â”‚   â””â”€â”€ logger.py                # Logging
â”‚   â”‚
â”‚   â””â”€â”€ scripts/                      # Scraping scriptleri
â”‚       â”œâ”€â”€ scraping.py              # Ana scraping script
â”‚       â””â”€â”€ test_scenario_generator.py
â”‚
â”œâ”€â”€ evaluators/                        # Model deÄŸerlendirme
â”‚   â””â”€â”€ arc.py                        # ARC evaluator
â”‚
â”œâ”€â”€ utils/                             # Genel yardÄ±mcÄ± araÃ§lar
â”‚   â””â”€â”€ functions.py                  # YardÄ±mcÄ± fonksiyonlar
â”‚
â”œâ”€â”€ logs/                              # Log dosyalarÄ±
â”‚   â”œâ”€â”€ scraping.log
â”‚   â””â”€â”€ scraping_errors.log
â”‚
â””â”€â”€ checkpoints/                       # Model checkpoints
    â””â”€â”€ [model_checkpoints]
```

---

## ğŸ”§ KonfigÃ¼rasyon

### Scraping KonfigÃ¼rasyonu

`scraping/config/scraping_config.yaml`:

```yaml
scraping:
  websites:
    - name: "trendyol"
      enabled: true
      max_products: 500
      categories: ["teknoloji", "ev", "guzellik"]
  
rate_limit:
  requests_per_minute: 20
  delay_between_requests: [2, 5]
  max_concurrent_requests: 10

gemini:
  model: "gemini-1.5-flash"
  max_requests_per_day: 1000
  retry_attempts: 3

output:
  final_dataset_path: "data/gift_catalog.json"
  user_scenarios_path: "data/user_scenarios.json"
  num_user_scenarios: 100
```

### Model KonfigÃ¼rasyonu

`config/cfg_pretrain.yaml`:

```yaml
# Data paths
data_paths: ['data/gift_recommendation']
data_paths_test: []

# Training hyperparameters
global_batch_size: 768
epochs: 100000
eval_interval: 10000

lr: 1e-4
lr_min_ratio: 1.0
lr_warmup_steps: 2000

weight_decay: 0.1
beta1: 0.9
beta2: 0.95

# Model architecture
arch:
  name: integrated_enhanced_trm
  hidden_size: 512
  num_heads: 8
  L_layers: 3
  H_layers: 3
```

---

## ğŸ“ˆ DeÄŸerlendirme

### Metrikler

Model performansÄ± ÅŸu metriklerle deÄŸerlendirilir:

1. **Recommendation Accuracy**: Ã–nerilen hediyelerin doÄŸruluÄŸu
2. **Category Match Score**: Kategori eÅŸleÅŸme skoru
3. **Budget Compliance**: BÃ¼tÃ§eye uygunluk oranÄ±
4. **User Satisfaction**: KullanÄ±cÄ± memnuniyeti (simÃ¼le edilmiÅŸ)
5. **Tool Usage Efficiency**: Tool kullanÄ±m verimliliÄŸi
6. **Diversity Score**: Ã–neri Ã§eÅŸitliliÄŸi

### DeÄŸerlendirme Scripti

```python
from evaluators.arc import ARCEvaluator

# Evaluator oluÅŸtur
evaluator = ARCEvaluator(
    data_path="data/gift_recommendation",
    eval_metadata=eval_metadata
)

# DeÄŸerlendirme yap
metrics = evaluator.result(save_path="results/")

print(f"Accuracy: {metrics['accuracy']:.2%}")
print(f"Category Match: {metrics['category_match']:.2%}")
print(f"Budget Compliance: {metrics['budget_compliance']:.2%}")
```

---

## ğŸ¤ KatkÄ±da Bulunma

KatkÄ±larÄ±nÄ±zÄ± bekliyoruz! LÃ¼tfen ÅŸu adÄ±mlarÄ± takip edin:

1. **Fork** edin
2. Feature branch oluÅŸturun (`git checkout -b feature/amazing-feature`)
3. DeÄŸiÅŸikliklerinizi commit edin (`git commit -m 'Add amazing feature'`)
4. Branch'inizi push edin (`git push origin feature/amazing-feature`)
5. **Pull Request** aÃ§Ä±n

### GeliÅŸtirme KurallarÄ±

- Code style: PEP 8
- Docstring: Google style
- Type hints kullanÄ±n
- Unit testler ekleyin
- README'yi gÃ¼ncelleyin

---

## ğŸ“ Lisans

Bu proje MIT lisansÄ± altÄ±nda lisanslanmÄ±ÅŸtÄ±r. Detaylar iÃ§in [LICENSE](LICENSE) dosyasÄ±na bakÄ±n.

---

## ğŸ™ TeÅŸekkÃ¼rler

- **TRM Architecture**: Tiny Recursive Model mimarisi iÃ§in
- **PyTorch**: Derin Ã¶ÄŸrenme framework'Ã¼ iÃ§in
- **Gemini API**: AI enhancement iÃ§in
- **SDV**: Synthetic data generation iÃ§in
- **Playwright**: Web scraping iÃ§in

---

## ğŸ“§ Ä°letiÅŸim

SorularÄ±nÄ±z veya Ã¶nerileriniz iÃ§in:

- **Email**: your.email@example.com
- **GitHub Issues**: [Issues](https://github.com/yourusername/trm-gift-recommendation/issues)

---

## ğŸ”® Gelecek PlanlarÄ±

- [ ] Multi-modal input support (resim, ses)
- [ ] Real-time recommendation API
- [ ] Web interface
- [ ] Mobile app
- [ ] Daha fazla e-ticaret sitesi desteÄŸi
- [ ] Collaborative filtering entegrasyonu
- [ ] A/B testing framework
- [ ] Production deployment guide

---

**â­ Projeyi beÄŸendiyseniz yÄ±ldÄ±z vermeyi unutmayÄ±n!**
